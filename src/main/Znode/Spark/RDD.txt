RDD : 弹性 分布式 数据集
    抽象类，装饰者设计模式
        弹性：
            存储弹性：内存与磁盘自动切换
            容错弹性：数据丢失可自动恢复
            计算弹性：计算出错重试机制
            分片弹性：可根据需要重新分片

        分布式： 数据存储在集群的不同节点上 跨机器

        数据集： 和容器的区别  只封装了计算逻辑,并不保存数据

            创建3中方式：
                1.集合创建：parallelize和makeRDD
                2.内部存储创建：textFile 本地文件, HDFS、HBase等
                3.其他RDD转换


        数据抽象： 抽象类，需要子类具体实现

        不可变： 计算逻辑不可变,想要改变只能创建新的RDD

        分布式，可分区,并行计算： 每个分区都有一个Executer


    RDD的特性: 分区器、首选位置、计算方法、依赖关系、分区
        1.有多个分区 ：分区是数据集的基本单位
                2.一个计算每个分区的逻辑：计算是以分片为单位的，每个RDD都会实现compute函数以达到这个目的

        3.RDD之间的依赖关系： RDD 的每次转换都会生成一个新的 RDD，
                         所以 RDD 之间会形成类似于流水线一样的前后依赖关系。

        4.一个Partitioner： 对存储键值对的 RDD，还有一个可选的分区器
                         只有对于 key-value的 RDD，才会有 Partitioner,
                         非key-value的 RDD 的 Partitioner 的值是 None;
                         Partitiner 不但决定了 RDD 的本区数量, 也决定了 parent RDD Shuffle 输出时的分区数量

        5.优先位置： 存储每个切片优先(preferred location)位置的列表
                    比如对于一个 HDFS 文件来说, 这个列表保存的就是每个 Partition 所在文件块的位置.
                    按照“移动数据不如移动计算”的理念, Spark 在进行任务调度的时候,
                    会尽可能地将计算任务分配到其所要处理数据块的存储位置.

        编程模式：在Spaark中，RDD被视为对象，RDD经过一系列的transformations转换定于之后
                    再调用actions触发RDD计算。来向程序返回结果或想存储系统保存数据
                    只有遇到action才会执行RDD的计算（延时计算）


    分区器：只有Key-Value类型的RDD才有分区器，非Key-Value类型的RDD分区的值是None
         Hash：默认
         Ranger：将一定范围的数映射到某个分区，不能保证顺序
                        该分区器要求RDD的k必须可排序
         自定义

    RDD序列化：类继承scala.Serializable
            初始化工作在Driver端，而代码执行在Executor端，涉及到跨进程通信，所以要序列化

          算子以外的代码都是在Driver端执行
          算子里面的代码都是在Executor端执行

      Kryo序列化机制
        Java的序列化能够序列化任何的类。但是比较重，序列化后对象的提交也比较大.
        出于性能的考虑，Spark2.0开始支持另外一种Kryo序列化机制，Kryo速度快
        Spark内部使用kryo来序列化:当RDD在Shuffle数据的时候,简单数据类型、数组和字符串类型
            使用kryo序列化，也要继承Serializable接口。
            dataFream和dataSet应用Kryo序列化

    RDD 依赖&血缘 :
        lineage保存了RDD的依赖关系(RDD的元数据信息和转换行为)

            当该RDD的部分分区数据丢失时，它可以根据这些信息来重新运算和恢复丢失的数据分区。

          血缘：RDD.toDebugString
          依赖：RDD.dependencies

          窄依赖：(分区数只能不变或者减少,而且一个分区的数据只能进入另一个分区)
          宽依赖：涉及Shuffle(分区数可以改变,数据打乱重组,重新分区)
            宽依赖对 Spark 去评估一个 transformations 有更加重要的影响, 比如对性能的影响.(涉及Shuffle（重新分区，数据倾斜）)

    DAG有向无环图：
        DAG记录了RDD的转换过程和任务的阶段。

    RDD持久化
        RDD 缓存(Cache & persist) 将前面的计算结果(此RDD)缓存
            两个方法被调用时 不是立即缓存，而是触发后面的action时，该RDD将会被缓存在计算节点的内存中，并供后面重用
            Cache操作会增加血缘关系，且不改变原有血缘关系
             缓存有可能丢失，或者存储于内存的数据由于内存不足而被删除，RDD缓存容错机制保证了缓存丢失也能保证计算的正确执行。
             由于RDD的各个Partition是相对独立的，因此只需要计算丢失的部分即可，并不需要重算全部Partition。

           ps自带缓存的算子：ReduceByKey等
             当一个节点Shuffle失败了避免重新计算整个输入。
             在实际使用的时候，如果想重用数据，仍然建议调用persist或cache
             如果使用完了缓存，可以通过unpersist() 方法释放缓存

        RDD 检查点ChickPoint，将RDD中间结果写入HDFS&磁盘
            血缘依赖过长会造成容错成本过高,如果检查点之后有节点出现问题，可以从检查点开始重做血缘，减少了开销
            检查点会切断血缘关系，必须执行Action操作才能触发。
            但是检查点为了数据安全，会从血缘关系的最开始执行一遍，所以一般和Cache一起使用，减少开销
          ps 在设置检查点是，要提前设置检查点存储路径 sc.setCheckpointDir
            检查点数据存储格式为：二进制的文件

        二者区别：
            1.是否切断血缘
            2.存储位置
                Cache存在内存或磁盘 可靠性低
                CheckPoint可存在HDFS等文件系统 可靠性高